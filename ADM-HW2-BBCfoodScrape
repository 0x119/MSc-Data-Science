import math
import requests
import pandas as pd
from bs4 import BeautifulSoup
#
#from string import ascii_lowercase
#ingredients= set()
#for c in ascii_lowercase:
#    print("fetcing letter " + c)
#    url = requests.get("http://www.bbc.co.uk/food/ingredients/by/letter/" + c)
#    soup = BeautifulSoup(url.text, "lxml") 
#    data = soup.find_all("li", {"class":"resource food"})
#    for link in data:
#        ingredients.add(link.get('id'))
# 
# In[268]:
def extract_recipe(ingredient):
    url_1 = requests.get("http://www.bbc.co.uk/food/"+ingredient)
    soup_1 = BeautifulSoup(url_1.text, 'lxml')
    g_data_1 = soup_1.find_all("a", {"class":"see-all-search"})
    recipes = set()
    if len(g_data_1) != 0:
        key = g_data_1[0].get('href')[30:]
        url_2 = requests.get("http://www.bbc.co.uk/food/recipes/search?keywords="+key)
        soup_2 = BeautifulSoup(url_2.text, 'lxml')
        g_data_2 = soup_2.find_all("div", {"class":"left"})
        for item in g_data_2:
            recipes.add(item.contents[0].find_all("a")[0].get('href')[14:])
        next_page = soup_2.find_all("ol", {"class":"pagInfo-page-numbers"})
        i = 2
        while(next_page[1].contents[-1] != 'Next'):
            url_3 = requests.get("http://www.bbc.co.uk/food/recipes/search?page="+str(i)+"&keywords="+key)
            soup_3 = BeautifulSoup(url_3.text, 'lxml')
            g_data_3 = soup_3.find_all("div", {"class":"left"})
            next_page = soup_3.find_all("ol", {"class":"pagInfo-page-numbers"})
            for item in g_data_3:
                recipes.add(item.contents[0].find_all("a")[0].get('href')[14:])
                next_page = soup_3.find_all("li", {"class":"pagInfo-page-numbers-next"})
            i += 1
    return recipes
# In[ Extract-All-Info]

def extract_All(recipe):
    url = requests.get("http://www.bbc.co.uk/food/recipes/"+recipe)
    soup = BeautifulSoup(url.text, 'lxml')
    l = []
    l.append(soup.title.contents[0][21:])
    g_data = soup.find_all("a", {"class":"chef__link","itemprop":"author"})
    if g_data == []:
        l.append('Unknown')
    else:
        l.append(g_data[0].text)
    classi = ['recipe-metadata__prep-time','recipe-metadata__cook-time','recipe-metadata__serving']
    for i in classi:
        g_data = soup.find_all("p", {"class":i})
        if g_data == []:
            l.append('Unknown')
        else:
            l.append(g_data[0].text)
    g_data = soup.find_all("div", {"class":"recipe-metadata__dietary"})
    if g_data == []:
        l.append('Unspecified')
    else:
        l.append(g_data[0].find_all('a')[0].get('href')[12:])
    ingredients = []
    g_data = soup.find_all("li", {"class":"recipe-ingredients__list-item"})
    for item in g_data:
        ingredients.append(item.text)
    l.append(ingredients)
    g_data = soup.find_all("ol", {"class":"recipe-method__list"})
    if g_data == []:
        l.append('Unknown')
    else:
        l.append(g_data[0].text.replace("\n", ""))
    return l

    
# In[8]:

def extract_Info(L):
    from collections import OrderedDict
    dict = OrderedDict()
    dict['Name'] = L[0]
    dict['Author'] = L[1]
    dict['PrepTime'] = L[2]
    dict['CookTime'] = L[3]
    dict['Serves'] = L[4]
    dict['Dietary'] = L[5]
    dict['Ingredients'] = L[6]
    dict['Method'] = L[7]
    return dict
    
# In[13]:

# ingredients = list(ingredients)

# In[273]:

#all_recipes = set()
#count = 1
#for i in ingredients[:]:
#    try:
#        all_recipes = all_recipes.union(extract_recipe(i))
#        if(len(all_recipes)==11224):
#            break
#        print(count,' -Ingrediente: '+i+ ' -Num. ricette trovate: ', len(all_recipes))
#        count += 1
#    except IndexError:
#        continue   


# In[119]:

#recipes = list(all_recipes)
##info_recipes = {}
#for x in recipes:
#    pos = recipes.index(x)
#    print(pos,' -Ricetta: '+x)
#    info_recipes[x] = extract_Info(extract_All(x))

# In[] ############################################


#ricette = info_recipes
#for i in info_recipes.keys():
#    ricette[i]['Name'] = info_recipes[i]['Name']
#    ricette[i]['Author'] = info_recipes[i]['Author'] 
#    ricette[i]['PrepTime'] = info_recipes[i]['PrepTime'] 
#    ricette[i]['CookTime'] = info_recipes[i]['CookTime'] 
#    ricette[i]['Serves'] = info_recipes[i]['Serves'] 
#    ricette[i]['Dietary'] = info_recipes[i]['Dietary'] 
#    ricette[i]['Ingredients'] = ('').join(info_recipes[i]['Ingredients'])
#    ricette[i]['Method'] = info_recipes[i]['Method'].replace('\r','')


# pd.DataFrame.from_dict(ricette, orient = 'index').to_csv('df_ricepes.csv', index = True)


def cosine_similarity(a, b):
    return sum([i*j for i,j in zip(a, b)])/(math.sqrt(sum([i*i for i in a]))*math.sqrt(sum([i*i for i in b])))

    
#dict_ingr = {}
#f = open('/Users/manfr/Desktop/ADM-Algorithmic Methods of Data Mining/HW02/Inv_Index_Ingr.csv', 'r')
#for row in csv.reader(f):
#    dict_ingr[''.join(row).split(';')[1]] = ''.join(row).split(';')[0]
#f.close()


#my_dict = dict()
#for k in ricette.keys():
#    query = ricette[k]['Ingredients'].lower()
#    l = []
#    for v in dict_ingr.keys():
#        pos = query.find(v)
#        if pos > 0:
#            l.append(int(dict_ingr[query[pos:pos+len(v)]]))
#            my_dict[k] = l

def find_recipes_with(dict_ingr,dict_recipe,ingredient):
    key = dict_ingr[ingredient]
    l = set()
    #for k,v in dict_recipe.items():
    #    if key in v:
    #        l.add(k)
    #return l
    for k,v in dict_recipe.items():
        if key in k:
            l.add(v)
    return l
#pd.DataFrame.from_dict(dict_ingr, orient = 'index').to_csv('dict_ingr.csv', index = True, header = False)
